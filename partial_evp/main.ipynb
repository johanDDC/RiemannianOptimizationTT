{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Подготовительный этап\n",
    "\n",
    "Обоснование происходящего будет [тут](https://raw.githubusercontent.com/johanDDC/RiemannianOptimizationTT/3af4e53147cd5a89dd53461d22775641cfddcd6e/partial_evp/evp.pdf)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import ttax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(1, 3, 1, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "m = random.randn(2, 3, 2)\n",
    "arr = jnp.array(random.randn(3, 2))\n",
    "print(arr.shape)\n",
    "arr = jnp.reshape(arr, (1, arr.shape[0], 1, arr.shape[1]), \"F\")\n",
    "print(arr.shape)\n",
    "arr = jnp.squeeze(arr)\n",
    "print(arr.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 2)\n",
      "[[[[-0.13728446  1.2043208 ]]\n",
      "\n",
      "  [[ 0.651604   -1.1579461 ]]\n",
      "\n",
      "  [[-3.2300212   0.44841063]]]\n",
      "\n",
      "\n",
      " [[[ 0.89420897 -0.01044754]]\n",
      "\n",
      "  [[ 0.28185886 -0.11538029]]\n",
      "\n",
      "  [[-0.06823526 -0.0543802 ]]]] \n",
      "\n",
      "(2, 3, 1, 2)\n",
      "(2, 1, 3, 2)\n",
      "[[[[-0.13728446  1.2043208 ]\n",
      "   [ 0.651604   -1.1579461 ]\n",
      "   [-3.2300212   0.44841063]]]\n",
      "\n",
      "\n",
      " [[[ 0.89420897 -0.01044754]\n",
      "   [ 0.28185886 -0.11538029]\n",
      "   [-0.06823526 -0.0543802 ]]]]\n",
      "(2, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "def core_extend_apply_and_shrink(core, func):\n",
    "    print(core.shape)\n",
    "    core = jnp.reshape(core, (core.shape[0], core.shape[1], 1, core.shape[2]), \"F\")\n",
    "    print(core, \"\\n\")\n",
    "    print(core.shape)\n",
    "    core = func(core)\n",
    "    print(core.shape)\n",
    "    print(core)\n",
    "    core = jnp.squeeze(core)\n",
    "    print(core.shape)\n",
    "    return core\n",
    "\n",
    "Core = jnp.array(np.array(m, order=\"F\"))\n",
    "# print(Core)\n",
    "Core = core_extend_apply_and_shrink(Core, lambda x: jnp.transpose(x, [0, 2, 1, 3]))\n",
    "# print(Core)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 2, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "tt_rank = random.randint(3, 6)\n",
    "modes = (2, 3, 2, 2)\n",
    "TT_op = ttax.random.tensor(jax.random.PRNGKey(42),\n",
    "                      modes, tt_rank=tt_rank, dtype=jnp.float32)\n",
    "TT_el = ttax.random.tensor(jax.random.PRNGKey(42),\n",
    "                      (3, 2), tt_rank=2, dtype=jnp.float32)\n",
    "print(TT_op.shape)\n",
    "print(TT_el.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def TT_matmul(tt1 : ttax.base_class.TT, tt2 : ttax.base_class.TT):\n",
    "    operator_cores = [\n",
    "        jnp.einsum('abi,icd->abcd', tt1.tt_cores[i], tt1.tt_cores[i + 1])\n",
    "        for i in range(0, len(tt1.tt_cores), 2)\n",
    "    ]\n",
    "    cores = [\n",
    "            jnp.einsum('abic,eig->aebcg', operator_cores[i], tt2.tt_cores[i]).reshape((\n",
    "                operator_cores[i].shape[0] * tt2.tt_ranks[i], operator_cores[i].shape[1],\n",
    "                operator_cores[i].shape[3] * tt2.tt_ranks[i + 1]), order=\"F\"\n",
    "            )\n",
    "        for i in range(len(tt2.tt_cores))\n",
    "    ]\n",
    "    return ttax.base_class.TT(cores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(TT_matmul(TT_op, TT_el).shape)\n",
    "# TT_matmul(TT_op, TT_el)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Основной этап"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "make_rayleigh = lambda A: lambda x: ttax.flat_inner(x, TT_matmul(A, x))\n",
    "norm = lambda x: jnp.sqrt(ttax.flat_inner(x, x))\n",
    "residual = lambda A, x, eig: norm(ttax.orthogonalize(TT_matmul(A, x) + (-eig) * x))\n",
    "retraction = lambda T: ttax.round(ttax.orthogonalize(T))\n",
    "\n",
    "def armijo_backtracking(init, grad, mul, beta, func, x):\n",
    "    alpha = init\n",
    "    while func(x) - func(retraction(x + (-alpha) * grad)) < \\\n",
    "        mul * alpha * norm(grad) ** 2:\n",
    "        alpha *= beta\n",
    "    return alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def riemanGD(A, init, tol, max_iter = None, debug = False):\n",
    "    rayleigh = make_rayleigh(A)\n",
    "    rieman_grad = ttax.autodiff.grad(rayleigh)\n",
    "    x = ttax.orthogonalize(init)\n",
    "    residuals = [residual(A, x, rayleigh(x))]\n",
    "    iters = 0\n",
    "    if debug == True:\n",
    "        print(\"№\\tresidual\")\n",
    "    while residual(A, x, rayleigh(x)) > tol:\n",
    "        # alpha = armijo_backtracking(jnp.inner(x, A @ rieman_grad(x)) / rayleigh(rieman_grad), rieman_grad, 1E-4, 0.8, rayleigh, x)\n",
    "        rieman_x = rieman_grad(x)\n",
    "        alpha = armijo_backtracking(2, rieman_x, 1E-4, 0.8, rayleigh, x)\n",
    "        x = retraction(x + (-alpha)*rieman_x)\n",
    "        iters += 1\n",
    "        residuals.append(residual(A, x, rayleigh(x)))\n",
    "        if debug == True:\n",
    "            print(\"{}\\t{}\".format(iters, residual(A, x, rayleigh(x))))\n",
    "        if (max_iter is not None and iters >= max_iter) or\\\n",
    "            (len(residuals) > 2 and residuals[-2] == residuals[-1]):\n",
    "            break\n",
    "\n",
    "    return x, residuals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 1. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0.]\n",
      "   [0. 0. 0. 1.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/PycharmProjects/RiemannianOptimizationTT/venv/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:3123: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax._check_user_dtype_supported(dtype, \"ones\")\n"
     ]
    }
   ],
   "source": [
    "core1 = np.zeros((1,4,4))\n",
    "core1[0,0,0] = core1[0,2,2] = core1[0,1,1] = core1[0, 3, 3] = 1\n",
    "core2 = np.zeros((4,4,4))\n",
    "core2[0,0,0] = core2[1,1,1] = core2[2,2,2] = core2[3,3,3] =  1\n",
    "core3 = core2.copy()\n",
    "core4 = np.zeros((4,4,1))\n",
    "core4[0,0,0] = core4[1,1,0] = core4[2,2,0] = core4[3,3,0] =  1\n",
    "I3 = jnp.array(core2)\n",
    "eye = ttax.base_class.TT(\n",
    "    [core1,core2, core3, core4]\n",
    ")\n",
    "print(ttax.full(eye))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№\tresidual\n",
      "1\t13.222766876220703\n",
      "2\t5.255079746246338\n",
      "3\t2.1720805168151855\n",
      "4\t0.9408542513847351\n",
      "5\t0.4378170073032379\n",
      "6\t0.22417989373207092\n",
      "7\t0.12597201764583588\n",
      "8\t0.0755133107304573\n",
      "9\t0.046871837228536606\n",
      "10\t0.02956838347017765\n",
      "11\t0.018783463165163994\n",
      "12\t0.011966923251748085\n",
      "13\t0.007633518893271685\n",
      "14\t0.004871348850429058\n",
      "15\t0.003109496086835861\n",
      "16\t0.0019851604010909796\n",
      "17\t0.0012669748393818736\n",
      "18\t0.0008088692557066679\n",
      "19\t0.000516400090418756\n",
      "20\t0.0003302779223304242\n"
     ]
    }
   ],
   "source": [
    "t = ttax.random.tensor(jax.random.PRNGKey(42),(4,4))\n",
    "# print(rieman_grad(t)(t))\n",
    "v, rs = riemanGD(eye, t, 4E-4, 20, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0583811e-07\n",
      "TT(tt_cores=[DeviceArray([[[ 0.2738081 , -1.8865969 , -0.15656863,  0.02251866],\n",
      "              [ 3.6740274 ,  0.37656114,  0.06663801,  0.00401304],\n",
      "              [ 0.38965422, -1.8502033 ,  0.21931557, -0.02004351],\n",
      "              [-0.70135784,  0.20815684,  0.40980142,  0.0186777 ]]],            dtype=float32), DeviceArray([[[ 0.6014823 ],\n",
      "              [-0.08720207],\n",
      "              [-0.7904917 ],\n",
      "              [ 0.07575009]],\n",
      "\n",
      "             [[ 0.04094949],\n",
      "              [ 0.78495234],\n",
      "              [-0.11366284],\n",
      "              [-0.60766244]],\n",
      "\n",
      "             [[ 0.6275646 ],\n",
      "              [ 0.39845207],\n",
      "              [ 0.47835764],\n",
      "              [ 0.4675172 ]],\n",
      "\n",
      "             [[ 0.49265072],\n",
      "              [-0.46634927],\n",
      "              [ 0.36520922],\n",
      "              [-0.637523  ]]], dtype=float32)])\n"
     ]
    }
   ],
   "source": [
    "print(make_rayleigh(eye)(v))\n",
    "print(v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}